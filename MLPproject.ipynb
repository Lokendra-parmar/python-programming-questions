{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/fQMHaYzh1HwHzpLLGyA9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lokendra-parmar/python-programming-questions/blob/main/MLPproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvsuiNVuMWa5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load all necessary files\n",
        "try:\n",
        "    booknow_booking_df = pd.read_csv('booknow_booking.csv')\n",
        "    cinepos_booking_df = pd.read_csv('cinePOS_booking.csv')\n",
        "    id_relation_df = pd.read_csv('movie_theater_id_relation.csv')\n",
        "    booknow_visits_df = pd.read_csv('booknow_visits.csv')\n",
        "    date_info_df = pd.read_csv('date_info.csv')\n",
        "    booknow_theaters_df = pd.read_csv('booknow_theaters.csv')\n",
        "\n",
        "    print(\"All files loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading files: {e}\")\n",
        "    # Stop execution if files can't be loaded\n",
        "    raise e\n",
        "\n",
        "print(\"Starting data consolidation...\")\n",
        "\n",
        "# --- 1a: Clean booknow_theaters ---\n",
        "# Drop rows where book_theater_id is null, as they cannot be linked\n",
        "booknow_theaters_df.dropna(subset=['book_theater_id'], inplace=True)\n",
        "# We'll ignore lat/lon and sparse theater_type/area for this model\n",
        "booknow_theaters_df = booknow_theaters_df[['book_theater_id']]\n",
        "\n",
        "# --- 1b: Process booknow_booking (Online) ---\n",
        "# Convert to datetime and get the date part\n",
        "booknow_booking_df['show_datetime'] = pd.to_datetime(booknow_booking_df['show_datetime'])\n",
        "booknow_booking_df['show_date'] = booknow_booking_df['show_datetime'].dt.strftime('%Y-%m-%d')\n",
        "# Aggregate: sum tickets by theater and date\n",
        "booknow_agg_df = booknow_booking_df.groupby(['book_theater_id', 'show_date'])['tickets_booked'].sum().reset_index()\n",
        "booknow_agg_df.rename(columns={'tickets_booked': 'total_booknow_tickets'}, inplace=True)\n",
        "\n",
        "# --- 1c: Process cinePOS_booking (On-site) ---\n",
        "# Convert to datetime and get the date part\n",
        "cinepos_booking_df['show_datetime'] = pd.to_datetime(cinepos_booking_df['show_datetime'])\n",
        "cinepos_booking_df['show_date'] = cinepos_booking_df['show_datetime'].dt.strftime('%Y-%m-%d')\n",
        "# Aggregate: sum tickets by theater and date\n",
        "cinepos_agg_df = cinepos_booking_df.groupby(['cine_theater_id', 'show_date'])['tickets_sold'].sum().reset_index()\n",
        "cinepos_agg_df.rename(columns={'tickets_sold': 'total_cinepos_tickets'}, inplace=True)\n",
        "\n",
        "# --- 1d: Link cinePOS to booknow IDs ---\n",
        "cinepos_linked_df = pd.merge(cinepos_agg_df, id_relation_df, on='cine_theater_id', how='inner')\n",
        "# Re-aggregate in case multiple cinePOS IDs map to a single book_theater_id\n",
        "cinepos_linked_agg_df = cinepos_linked_df.groupby(['book_theater_id', 'show_date'])['total_cinepos_tickets'].sum().reset_index()\n",
        "\n",
        "# --- 1e: Create Master DataFrame ---\n",
        "# Start with the base visits data (our target)\n",
        "master_df = booknow_visits_df.copy()\n",
        "\n",
        "# Merge calendar info\n",
        "master_df = pd.merge(master_df, date_info_df, on='show_date', how='left')\n",
        "\n",
        "# Merge aggregated BookNow bookings\n",
        "master_df = pd.merge(master_df, booknow_agg_df, on=['book_theater_id', 'show_date'], how='left')\n",
        "\n",
        "# Merge aggregated and linked CinePOS bookings\n",
        "master_df = pd.merge(master_df, cinepos_linked_agg_df, on=['book_theater_id', 'show_date'], how='left')\n",
        "\n",
        "# --- 1f: Final Cleanup ---\n",
        "# Fill booking NaNs with 0 (days with visits but no recorded online/POS bookings)\n",
        "master_df['total_booknow_tickets'].fillna(0, inplace=True)\n",
        "master_df['total_cinepos_tickets'].fillna(0, inplace=True)\n",
        "\n",
        "# Convert show_date to datetime object for sorting and feature engineering\n",
        "master_df['show_date'] = pd.to_datetime(master_df['show_date'])\n",
        "\n",
        "print(\"--- Master DataFrame Created ---\")\n",
        "print(master_df.head())\n",
        "print(f\"\\nShape of master_df: {master_df.shape}\")\n",
        "print(master_df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Feature Engineering & Model Validation"
      ],
      "metadata": {
        "id": "UvSxegRaNEPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print(\"\\n--- Starting Step 2: Feature Engineering & Validation ---\")\n",
        "\n",
        "# --- 2a: Create Features ---\n",
        "# Create 'total_tickets' feature\n",
        "master_df['total_tickets'] = master_df['total_booknow_tickets'] + master_df['total_cinepos_tickets']\n",
        "\n",
        "# Date Features\n",
        "master_df['day_of_month'] = master_df['show_date'].dt.day\n",
        "master_df['month'] = master_df['show_date'].dt.month\n",
        "master_df['year'] = master_df['show_date'].dt.year\n",
        "master_df['day_of_year'] = master_df['show_date'].dt.dayofyear\n",
        "master_df['is_weekend'] = master_df['day_of_week'].isin(['Saturday', 'Sunday']).astype(int)\n",
        "\n",
        "# CRITICAL: Sort by theater and date\n",
        "master_df = master_df.sort_values(by=['book_theater_id', 'show_date'])\n",
        "\n",
        "# Lag & Rolling Features\n",
        "print(\"Creating lag and rolling features...\")\n",
        "gb = master_df.groupby('book_theater_id')['audience_count']\n",
        "master_df['audience_lag_7'] = gb.shift(7)\n",
        "master_df['audience_lag_14'] = gb.shift(14)\n",
        "master_df['audience_roll_mean_7'] = gb.shift(1).rolling(7, min_periods=1).mean()\n",
        "\n",
        "# --- 2b: Categorical Encoding ---\n",
        "# We will use LabelEncoder for IDs and One-Hot Encoding for 'day_of_week'\n",
        "le = LabelEncoder()\n",
        "master_df['book_theater_id_encoded'] = le.fit_transform(master_df['book_theater_id'])\n",
        "master_df = pd.get_dummies(master_df, columns=['day_of_week'], prefix='dow')\n",
        "\n",
        "# --- 2c: Clean Data ---\n",
        "# Drop rows where lag features are NaN (at the start of each series)\n",
        "master_df_cleaned = master_df.dropna()\n",
        "print(f\"Data shape after feature engineering and cleaning: {master_df_cleaned.shape}\")\n",
        "\n",
        "# --- 2d: Time-Series Split for Validation ---\n",
        "target_col = 'audience_count'\n",
        "# Exclude original IDs and date\n",
        "features = [col for col in master_df_cleaned.columns if col not in [\n",
        "    'audience_count', 'show_date', 'book_theater_id'\n",
        "]]\n",
        "\n",
        "X = master_df_cleaned[features]\n",
        "y = master_df_cleaned[target_col]\n",
        "\n",
        "# We will use the last 4 weeks (28 days) for validation\n",
        "max_date = master_df_cleaned['show_date'].max()\n",
        "split_date = max_date - pd.to_timedelta('28 days')\n",
        "\n",
        "train_mask = (master_df_cleaned['show_date'] < split_date)\n",
        "valid_mask = (master_df_cleaned['show_date'] >= split_date)\n",
        "\n",
        "X_train, y_train = X[train_mask], y[train_mask]\n",
        "X_valid, y_valid = X[valid_mask], y[valid_mask]\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Validation data shape: {X_valid.shape}\")\n",
        "\n",
        "# --- 2e: Train and Validate Model ---\n",
        "print(\"\\nTraining RandomForestRegressor for validation...\")\n",
        "# Use a fast and powerful RandomForest\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    min_samples_leaf=5,\n",
        "    max_features=0.7\n",
        ")\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = rf.predict(X_valid)\n",
        "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
        "print(f\"\\n--- Validation Complete ---\")\n",
        "print(f\"Validation RMSE: {rmse:.4f}\")\n",
        "print(\"This shows our model is predictive. Now we will build the final submission.\")"
      ],
      "metadata": {
        "id": "XdhawvAYM_qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Create Full Dataset for Submission"
      ],
      "metadata": {
        "id": "aedKBYJ5NInq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from itertools import product\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "print(\"\\n--- Starting Step 3: Creating Full Train+Test Dataset ---\")\n",
        "\n",
        "# --- 3a: Reload original data ---\n",
        "# We need the original files to build the full train+test set\n",
        "booknow_visits_df = pd.read_csv('booknow_visits.csv')\n",
        "date_info_df = pd.read_csv('date_info.csv')\n",
        "\n",
        "# --- 3b: Identify Test Period ---\n",
        "booknow_visits_df['show_date'] = pd.to_datetime(booknow_visits_df['show_date'])\n",
        "date_info_df['show_date'] = pd.to_datetime(date_info_df['show_date'])\n",
        "max_train_date = booknow_visits_df['show_date'].max()\n",
        "test_dates_df = date_info_df[date_info_df['show_date'] > max_train_date]\n",
        "print(f\"Test period identified: {test_dates_df['show_date'].min().date()} to {test_dates_df['show_date'].max().date()}\")\n",
        "\n",
        "# --- 3c: Create Test Scaffolding ---\n",
        "all_theater_ids = booknow_visits_df['book_theater_id'].unique()\n",
        "test_scaffold_df = pd.DataFrame(product(all_theater_ids, test_dates_df['show_date']),\n",
        "                                columns=['book_theater_id', 'show_date'])\n",
        "print(f\"Test scaffold created with shape: {test_scaffold_df.shape}\")\n",
        "\n",
        "# --- 3d: Combine Train and Test ---\n",
        "# `audience_count` will be NaN for the test pairs\n",
        "full_data_df = pd.concat([booknow_visits_df, test_scaffold_df], sort=True)\n",
        "full_data_df = full_data_df.sort_values(by=['book_theater_id', 'show_date']).reset_index(drop=True)\n",
        "\n",
        "# --- 3e: Re-run Feature Engineering on Full Dataset ---\n",
        "# We re-use the aggregated DataFrames from Step 1\n",
        "print(\"Merging all features into full dataset...\")\n",
        "full_master_df = pd.merge(full_data_df, date_info_df, on='show_date', how='left')\n",
        "full_master_df = pd.merge(full_master_df, booknow_agg_df, on=['book_theater_id', 'show_date'], how='left')\n",
        "full_master_df = pd.merge(full_master_df, cinepos_linked_agg_df, on=['book_theater_id', 'show_date'], how='left')\n",
        "\n",
        "# Cleanup NaNs\n",
        "full_master_df['total_booknow_tickets'].fillna(0, inplace=True)\n",
        "full_master_df['total_cinepos_tickets'].fillna(0, inplace=True)\n",
        "full_master_df['total_tickets'] = full_master_df['total_booknow_tickets'] + full_master_df['total_cinepos_tickets']\n",
        "\n",
        "# Date Features\n",
        "full_master_df['day_of_month'] = full_master_df['show_date'].dt.day\n",
        "full_master_df['month'] = full_master_df['show_date'].dt.month\n",
        "full_master_df['year'] = full_master_df['show_date'].dt.year\n",
        "full_master_df['day_of_year'] = full_master_df['show_date'].dt.dayofyear\n",
        "full_master_df['is_weekend'] = full_master_df['day_of_week'].isin(['Saturday', 'Sunday']).astype(int)\n",
        "\n",
        "# Lag & Rolling Features\n",
        "# This now correctly uses train data to create lags for the test data\n",
        "print(\"Creating lags on full dataset...\")\n",
        "gb_full = full_master_df.groupby('book_theater_id')['audience_count']\n",
        "full_master_df['audience_lag_7'] = gb_full.shift(7)\n",
        "full_master_df['audience_lag_14'] = gb_full.shift(14)\n",
        "full_master_df['audience_roll_mean_7'] = gb_full.shift(1).rolling(7, min_periods=1).mean()\n",
        "\n",
        "# Categorical Encoding\n",
        "full_master_df['book_theater_id_encoded'] = le.transform(full_master_df['book_theater_id']) # Use the LE from Step 2\n",
        "full_master_df = pd.get_dummies(full_master_df, columns=['day_of_week'], prefix='dow')\n",
        "\n",
        "print(\"--- Full Train+Test Dataset is Ready ---\")\n",
        "print(full_master_df.info())"
      ],
      "metadata": {
        "id": "s0H0ImjrNNRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Final Model Training & Submission"
      ],
      "metadata": {
        "id": "85nmUKffNP_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "print(\"\\n--- Starting Step 4: Final Training & Submission ---\")\n",
        "\n",
        "# --- 4a: Split into Final Train and Test ---\n",
        "# Training data is where 'audience_count' is known\n",
        "train_final_df = full_master_df[full_master_df['audience_count'].notnull()]\n",
        "# Test data is where 'audience_count' is unknown\n",
        "test_final_df = full_master_df[full_master_df['audience_count'].isnull()]\n",
        "\n",
        "# Clean the final training data (drop initial NaNs)\n",
        "train_final_df = train_final_df.dropna(subset=['audience_lag_7', 'audience_lag_14', 'audience_roll_mean_7'])\n",
        "\n",
        "print(f\"Final training data shape: {train_final_df.shape}\")\n",
        "print(f\"Final test data shape: {test_final_df.shape}\")\n",
        "\n",
        "# --- 4b: Align Columns ---\n",
        "# Get feature list from the training set\n",
        "features = [col for col in train_final_df.columns if col not in [\n",
        "    'audience_count', 'show_date', 'book_theater_id'\n",
        "]]\n",
        "\n",
        "# Ensure test set has the exact same columns as the train set\n",
        "X_train_final = train_final_df[features]\n",
        "y_train_final = train_final_df[target_col]\n",
        "\n",
        "# Align test set columns\n",
        "X_test_final = test_final_df.copy()\n",
        "for col in features:\n",
        "    if col not in X_test_final.columns:\n",
        "        X_test_final[col] = 0\n",
        "X_test_final = X_test_final[features] # Keep only feature columns in correct order\n",
        "\n",
        "# Handle any NaNs in test features (e.g., if a new theater had no lag data)\n",
        "# For this problem, we'll fill with 0\n",
        "X_test_final.fillna(0, inplace=True)\n",
        "\n",
        "# --- 4c: Train Final Model ---\n",
        "print(\"Training final model on ALL available data...\")\n",
        "rf_final = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    min_samples_leaf=5,\n",
        "    max_features=0.7\n",
        ")\n",
        "rf_final.fit(X_train_final, y_train_final)\n",
        "print(\"Final model trained.\")\n",
        "\n",
        "# --- 4d: Make Predictions ---\n",
        "print(\"Making final predictions...\")\n",
        "predictions = rf_final.predict(X_test_final)\n",
        "\n",
        "# --- 4e: Format Submission File ---\n",
        "submission_df = test_final_df[['book_theater_id', 'show_date']].copy()\n",
        "submission_df['audience_count'] = predictions\n",
        "\n",
        "# Format the ID: book_theater_id + show_date\n",
        "submission_df['show_date'] = submission_df['show_date'].dt.strftime('%Y-%m-%d')\n",
        "submission_df['ID'] = submission_df['book_theater_id'] + '_' + submission_df['show_date']\n",
        "\n",
        "# Ensure predictions are non-negative and integers\n",
        "submission_df['audience_count'] = np.round(submission_df['audience_count']).astype(int)\n",
        "submission_df.loc[submission_df['audience_count'] < 0, 'audience_count'] = 0\n",
        "\n",
        "# Select final columns\n",
        "final_submission = submission_df[['ID', 'audience_count']]\n",
        "\n",
        "# Save the file\n",
        "final_submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\n--- Submission File Created! ---\")\n",
        "print(final_submission.head())\n",
        "print(f\"File 'submission.csv' saved with {len(final_submission)} predictions.\")"
      ],
      "metadata": {
        "id": "vxFSnZKTNiZK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}